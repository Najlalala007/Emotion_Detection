{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fdc135-b6cd-43f9-9a3d-f47778d2363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa08df2f-0a26-465c-8c4b-b70153f8ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion                                               Text  \\\n",
      "0  neutral                                             Why ?    \n",
      "1      joy    Sage Act upgrade on my to do list for tommorow.   \n",
      "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
      "3      joy   Such an eye ! The true hazel eye-and so brill...   \n",
      "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
      "\n",
      "                                          Clean_Text  \n",
      "0                                                NaN  \n",
      "1                     Sage Act upgrade list tommorow  \n",
      "2  WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...  \n",
      "3  eye  true hazel eyeand brilliant  Regular feat...  \n",
      "4    ugh babe hugggzzz u  babe naamazed nga ako e...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('emotion_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ce85e6-1a00-459b-b911-1612829b865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(Text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(Text)\n",
    "    # Convert to lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove punctuation and stop words\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['processed_text'] = df['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0477e4ef-8ba1-4735-aa47-2a857844fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Labels to Numbers\n",
    "label_encoder = LabelEncoder()\n",
    "df['emotion_label'] = label_encoder.fit_transform(df['Emotion'])\n",
    "\n",
    "# Step 5: Split Features and Labels\n",
    "X = df['processed_text']\n",
    "y = df['emotion_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c92cd8-79e3-4ee0-b89c-436bf7dd9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebc1aa4-d9db-49d6-8d0d-f32b0512e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4ae181-e7b0-4e42-85fe-275714360e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36224cb8-1171-4997-9126-19e9a023878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model and Vectorizer\n",
    "joblib.dump(model, 'emotion_classifier_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad45f5fe-d289-4866-8e9e-df24ce11567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5068256933467452\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.25      0.40       836\n",
      "           1       0.00      0.00      0.00       202\n",
      "           2       0.88      0.42      0.57      1104\n",
      "           3       0.42      0.97      0.58      2214\n",
      "           4       0.95      0.08      0.14       481\n",
      "           5       0.64      0.40      0.49      1327\n",
      "           6       0.00      0.00      0.00        23\n",
      "           7       0.80      0.17      0.28       772\n",
      "\n",
      "    accuracy                           0.51      6959\n",
      "   macro avg       0.57      0.29      0.31      6959\n",
      "weighted avg       0.66      0.51      0.46      6959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazla\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nazla\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nazla\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc0ae66-47f0-4e15-b114-77385764e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "# Predict Emotions\n",
    "def predict_emotion(text):\n",
    "    # Load the saved model and vectorizer\n",
    "    loaded_model = joblib.load('emotion_classifier_model.pkl')\n",
    "    loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    loaded_label_encoder = joblib.load('label_encoder.pkl')\n",
    "    \n",
    "    processed_text = preprocess_text(text)\n",
    "    vectorized_text = loaded_vectorizer.transform([processed_text])\n",
    "    prediction = loaded_model.predict(vectorized_text)\n",
    "    emotion = loaded_label_encoder.inverse_transform(prediction)\n",
    "    return emotion[0]\n",
    "\n",
    "# Test the prediction function\n",
    "print(predict_emotion(\"I am so happy today!\"))\n",
    "print(predict_emotion(\"This is a terrible day.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a37ab-5f45-4df3-b85f-9a9b6beda969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
